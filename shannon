#!/bin/bash
# Shannon 命令行工具 - AI 渗透测试框架

set -e

# 检测 Podman 与 Docker 并相应设置 compose 文件
# Podman 不支持 host-gateway，因此我们只为实际的 Docker 包含 Docker 覆盖配置
COMPOSE_BASE="docker-compose.yml"
if command -v podman &>/dev/null; then
  # 检测到 Podman（原生或通过 Docker Desktop 垫片）- 仅使用基础配置
  COMPOSE_OVERRIDE=""
else
  # 检测到 Docker - 包含 extra_hosts 覆盖以实现 Linux localhost 访问
  COMPOSE_OVERRIDE="-f docker-compose.docker.yml"
fi
COMPOSE_FILE="$COMPOSE_BASE"

# 如果存在 .env 文件则加载
if [ -f .env ]; then
  set -a
  source .env
  set +a
fi

show_help() {
  cat << 'EOF'

  ███████╗██╗  ██╗ █████╗ ███╗   ██╗███╗   ██╗ ██████╗ ███╗   ██╗
  ██╔════╝██║  ██║██╔══██╗████╗  ██║████╗  ██║██╔═══██╗████╗  ██║
  ███████╗███████║███████║██╔██╗ ██║██╔██╗ ██║██║   ██║██╔██╗ ██║
  ╚════██║██╔══██║██╔══██║██║╚██╗██║██║╚██╗██║██║   ██║██║╚██╗██║
  ███████║██║  ██║██║  ██║██║ ╚████║██║ ╚████║╚██████╔╝██║ ╚████║
  ╚══════╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝  ╚═══╝╚═╝  ╚═══╝ ╚═════╝ ╚═╝  ╚═══╝

           AI 渗透测试框架

使用方法：
  ./shannon start URL=<url> REPO=<name>   启动渗透测试工作流
  ./shannon logs ID=<workflow-id>         跟踪特定工作流的日志
  ./shannon query ID=<workflow-id>        查询工作流进度
  ./shannon stop                          停止所有容器
  ./shannon help                          显示此帮助信息

'start' 选项：
  REPO=<name>            ./repos/ 下的文件夹名称（例如：REPO=repo-name）
  CONFIG=<path>          配置文件（YAML）
  OUTPUT=<path>          报告输出目录（默认：./audit-logs/）
  PIPELINE_TESTING=true  使用最小提示进行快速测试
  ROUTER=true            通过 claude-code-router 路由请求（多模型支持）

'stop' 选项：
  CLEAN=true             删除所有数据，包括卷

示例：
  ./shannon start URL=https://example.com REPO=repo-name
  ./shannon start URL=https://example.com REPO=repo-name CONFIG=./config.yaml
  ./shannon start URL=https://example.com REPO=repo-name OUTPUT=./my-reports
  ./shannon logs ID=example.com_shannon-1234567890
  ./shannon query ID=shannon-1234567890
  ./shannon stop CLEAN=true

在 http://localhost:8233 监控工作流
EOF
}

# 解析 KEY=value 格式的参数为变量
parse_args() {
  for arg in "$@"; do
    case "$arg" in
      URL=*) URL="${arg#URL=}" ;;
      REPO=*) REPO="${arg#REPO=}" ;;
      CONFIG=*) CONFIG="${arg#CONFIG=}" ;;
      OUTPUT=*) OUTPUT="${arg#OUTPUT=}" ;;
      ID=*) ID="${arg#ID=}" ;;
      CLEAN=*) CLEAN="${arg#CLEAN=}" ;;
      PIPELINE_TESTING=*) PIPELINE_TESTING="${arg#PIPELINE_TESTING=}" ;;
      REBUILD=*) REBUILD="${arg#REBUILD=}" ;;
      ROUTER=*) ROUTER="${arg#ROUTER=}" ;;
    esac
  done
}

# 检查 Temporal 是否运行且健康
is_temporal_ready() {
  docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE exec -T temporal \
    temporal operator cluster health --address localhost:7233 2>/dev/null | grep -q "SERVING"
}

# 确保容器运行且挂载正确
ensure_containers() {
  # 如果设置了自定义 OUTPUT_DIR，始终刷新 worker 以确保正确的卷挂载
  # Docker compose 只会在挂载实际更改时重新创建
  if [ -n "$OUTPUT_DIR" ]; then
    echo "确保 worker 有正确的输出挂载..."
    docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE up -d worker 2>/dev/null || true
  fi

  # 快速检查：如果 Temporal 已经健康，我们就完成了
  if is_temporal_ready; then
    return 0
  fi

  # 需要启动容器
  echo "启动 Shannon 容器..."
  if [ "$REBUILD" = "true" ]; then
    # 强制无缓存重建（当代码更改未被拾取时使用）
    echo "使用 --no-cache 重建..."
    docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE build --no-cache worker
  fi
  docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE up -d --build

  # 等待 Temporal 准备就绪
  echo "等待 Temporal 准备就绪..."
  for i in $(seq 1 30); do
    if is_temporal_ready; then
      echo "Temporal 已就绪！"
      return 0
    fi
    if [ "$i" -eq 30 ]; then
      echo "等待 Temporal 超时"
      exit 1
    fi
    sleep 2
  done
}

cmd_start() {
  parse_args "$@"

  # 验证必需变量
  if [ -z "$URL" ] || [ -z "$REPO" ]; then
    echo "错误: URL 和 REPO 是必需的"
    echo "使用方法: ./shannon start URL=<url> REPO=<name>"
    exit 1
  fi

  # 检查 API 密钥（路由器模式可以使用替代提供商的 API 密钥）
  if [ -z "$ANTHROPIC_API_KEY" ] && [ -z "$CLAUDE_CODE_OAUTH_TOKEN" ]; then
    if [ "$ROUTER" = "true" ] && { [ -n "$OPENAI_API_KEY" ] || [ -n "$OPENROUTER_API_KEY" ]; }; then
      # 路由器模式与替代提供商 - 为 SDK 初始化设置占位符
      export ANTHROPIC_API_KEY="router-mode"
    else
      echo "错误: 在 .env 中设置 ANTHROPIC_API_KEY 或 CLAUDE_CODE_OAUTH_TOKEN"
      echo "       (或使用 ROUTER=true 并设置 OPENAI_API_KEY 或 OPENROUTER_API_KEY)"
      exit 1
    fi
  fi

  # 确定 REPO 的容器路径
  # - 如果 REPO 已经是容器路径 (/benchmarks/*, /repos/*)，按原样使用
  # - 否则，将其视为 ./repos/ 下的文件夹名称（在容器中挂载为 /repos）
  case "$REPO" in
    /benchmarks/*|/repos/*) 
      CONTAINER_REPO="$REPO"
      ;;
    *)
      if [ ! -d "./repos/$REPO" ]; then
        echo "错误: 在 ./repos/$REPO 未找到仓库"
        echo ""
        echo "请将目标仓库放在 ./repos/ 目录下"
        exit 1
      fi
      CONTAINER_REPO="/repos/$REPO"
      ;;
  esac

  # 处理自定义 OUTPUT 目录
  # 在启动容器之前导出 OUTPUT_DIR 用于 docker-compose 卷挂载
  if [ -n "$OUTPUT" ]; then
    # 创建输出目录并为容器用户（UID 1001）设置写入权限
    mkdir -p "$OUTPUT"
    chmod 777 "$OUTPUT"
    export OUTPUT_DIR="$OUTPUT"
  fi

  # 处理 ROUTER 标志 - 启动 claude-code-router 以支持多模型
  if [ "$ROUTER" = "true" ]; then
    # 检查路由器是否已经运行
    if docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE --profile router ps router 2>/dev/null | grep -q "running"; then
      echo "路由器已经运行，跳过启动..."
    else
      echo "启动 claude-code-router..."

      # 检查提供商 API 密钥
      if [ -z "$OPENAI_API_KEY" ] && [ -z "$OPENROUTER_API_KEY" ]; then
        echo "警告: 未设置提供商 API 密钥 (OPENAI_API_KEY 或 OPENROUTER_API_KEY)。路由器可能无法工作。"
      fi

      # 使用配置文件启动路由器
      docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE --profile router up -d router

      # 给路由器几秒钟时间启动（健康检查暂时禁用 - TODO: 稍后调试）
      echo "等待路由器启动..."
      sleep 5
    fi

    # 设置 ANTHROPIC_BASE_URL 以通过路由器路由
    export ANTHROPIC_BASE_URL="http://router:3456"
    # 设置认证令牌以匹配路由器的 APIKEY
    export ANTHROPIC_AUTH_TOKEN="shannon-router-key"
  fi

  # 确保 audit-logs 目录存在并为容器用户（UID 1001）设置写入权限
  mkdir -p ./audit-logs
  chmod 777 ./audit-logs

  # 确保 repo deliverables 目录可由容器用户（UID 1001）写入
  if [ -d "./repos/$REPO" ]; then
    mkdir -p "./repos/$REPO/deliverables"
    chmod 777 "./repos/$REPO/deliverables"
  fi

  # 确保容器运行（如有需要则启动）
  ensure_containers

  # 构建可选参数
  ARGS=""
  [ -n "$CONFIG" ] && ARGS="$ARGS --config $CONFIG"

  # 传递输出的容器路径（OUTPUT_DIR 挂载的位置）
  # 同时传递显示路径，以便客户端可以向用户显示主机路径
  if [ -n "$OUTPUT" ]; then
    ARGS="$ARGS --output /app/output --display-output $OUTPUT"
  fi

  [ "$PIPELINE_TESTING" = "true" ] && ARGS="$ARGS --pipeline-testing"

  # 运行客户端提交工作流
  docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE exec -T worker \
    node dist/temporal/client.js "$URL" "$CONTAINER_REPO" $ARGS
}

cmd_logs() {
  parse_args "$@"

  if [ -z "$ID" ]; then
    echo "错误: ID 是必需的"
    echo "使用方法: ./shannon logs ID=<workflow-id>"
    exit 1
  fi

  # 自动发现工作流日志文件
  # 1. 首先检查默认位置
  # 2. 搜索常见输出目录
  # 3. 回退到 find 命令
  WORKFLOW_LOG=""

  if [ -f "./audit-logs/${ID}/workflow.log" ]; then
    WORKFLOW_LOG="./audit-logs/${ID}/workflow.log"
  else
    # 搜索工作流目录（处理自定义 OUTPUT 路径）
    FOUND=$(find . -maxdepth 3 -path "*/${ID}/workflow.log" -type f 2>/dev/null | head -1)
    if [ -n "$FOUND" ]; then
      WORKFLOW_LOG="$FOUND"
    fi
  fi

  if [ -n "$WORKFLOW_LOG" ]; then
    echo "跟踪工作流日志: $WORKFLOW_LOG"
    tail -f "$WORKFLOW_LOG"
  else
    echo "错误: 未找到 ID 为 $ID 的工作流日志"
    echo ""
    echo "可能的原因:"
    echo "  - 工作流尚未开始"
    echo "  - 工作流 ID 不正确"
    echo ""
    echo "检查: ./shannon query ID=$ID 获取工作流详情"
    exit 1
  fi
}

cmd_query() {
  parse_args "$@"

  if [ -z "$ID" ]; then
    echo "错误: ID 是必需的"
    echo "使用方法: ./shannon query ID=<workflow-id>"
    exit 1
  fi

  docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE exec -T worker \
    node dist/temporal/query.js "$ID"
}

cmd_stop() {
  parse_args "$@"

  if [ "$CLEAN" = "true" ]; then
    docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE --profile router down -v
  else
    docker compose -f "$COMPOSE_FILE" $COMPOSE_OVERRIDE --profile router down
  fi
}

# 主命令分发
case "${1:-help}" in
  start)
    shift
    cmd_start "$@"
    ;;
  logs)
    shift
    cmd_logs "$@"
    ;;
  query)
    shift
    cmd_query "$@"
    ;;
  stop)
    shift
    cmd_stop "$@"
    ;;
  help|--help|-h|*)
    show_help
    ;;
esac
